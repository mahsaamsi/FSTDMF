# FeatureÂ SubspaceÂ TransferÂ DeepÂ MatrixÂ FactorizationÂ (FSTâ€‘DMF)

## ðŸ“œÂ Paper in one sentence

**FSTâ€‘DMF** augments a target rating matrix with an **auxiliary view of the items**â€¯â€”â€¯either

1. **side attributes** of the same dataset (e.g. oneâ€‘hot year & genre) or
2. **an entire second rating matrix** (e.g. MovieLensâ€‘1M when the target is MovieLensâ€‘100K).

That auxiliary matrix is first converted into an orthonormal basis `V_A`. The model then makes use of it in two complementary ways:

* **Vâ€‘init.** A *latent matrix*Â `Îµ` produced by a semiâ€‘autoencoder (trained on the target rating matrix) is \*\*copied into the item embedding tableÂ \*\***`V`** before training.
* **Subâ€‘space loss.** A projection term keeps the learned item factors inside (or close to) the subâ€‘space spanned by `V_A`, so the knowledge encoded in the auxiliary view is preserved throughout training.
assets/1.png
---

## ðŸ”§Â Building the auxiliary matrixÂ `V_A`

| **Source of auxiliary info**                                                                                           | Preâ€‘processing pipeline                                                                                                                                                      |
| ---------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Item attributes** (e.g. year, genre) from the **same** dataset                                                       | 1ï¸âƒ£Â Oneâ€‘hot encode every categorical slot â†’ matrixâ€¯`C`â€‚2ï¸âƒ£Â Thinâ€‘QR/SVD â†’ orthonormal basis `V_A` with `V_A^T V_A = I`.                                                       |
| **Ratings of the same titles in aÂ **********************************second********************************** dataset** | 1ï¸âƒ£Â Keep only items present in *both* domainsâ€‚2ï¸âƒ£Â Feed the source rating matrix to a **semiâ€‘autoencoder**; grab the hidden layer Îµâ€‚3ï¸âƒ£Â Thinâ€‘QR/SVD â†’ orthonormalise â†’ `V_A`. |

At training time we never change `V_A`; it stays fixed while the targetâ€‘domain item matrix `V` is **(i) initialised from it and (ii) nudged back toward its subâ€‘space** by the projection loss.
assets/1.png

---

## Why "plain" DeepÂ MatrixÂ Factorization (DMF) is not enough (DMF) is not enough

| Challenge                        | What happens with plain DMF?                                                                                                                   |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| *Data sparsity* in small domains | DMF learns item/user embeddings from scratch; with only a few ratings it easily **overâ€‘fits**.                                                 |
| *Coldâ€‘start across domains*      | Items that exist in both MovieLensâ€‘1M and MovieLensâ€‘100K end up with **incompatible embeddings**, so knowledge in the larger domain is wasted. |
| *Latent space drift*             | Without additional constraints, the learned space may rotate/scale unpredictably between runs, making crossâ€‘domain comparison hard.            |

FSTâ€‘DMF answers all three issues: it **initialises** the item matrix with a wellâ€‘shaped latent space obtained from the big domain and **locks** that space during fineâ€‘tuning.

---

## The two key innovations

### 1. `Vâ€‘init`Â â€“Â latent seed from a semiâ€‘autoencoder

1. Feed the chosen rating matrix (target domain (MovieLensâ€‘100K)) into a *semiâ€‘autoencoder*.
2. Take the hidden layer outputÂ `Îµâ€¯âˆˆâ€¯â„^{nÃ—d}` **without orthogonalising** it.
3. Copy each row of `Îµ` into the corresponding row of the itemâ€‘factor matrixÂ `V` as the starting point for DMF.

### 2. Subâ€‘space consistency loss

During training on MovieLensâ€‘100K we add

$$
\mathcal{L}_{\text{sub}} = -\frac{\alpha\,\eta}{2n}\,\bigl\| V_A V_A^{\top} V \bigr\|_F^{2}
$$

which maximises the alignment between the learned item matrix $V$ and the fixed subâ€‘space spanned by $V_A$.

* High $\eta$Â â†’ stronger pull when the two datasets are very similar.
* $\alpha$ comes from the paperâ€™s hyperâ€‘parameter grid.

---

## Complete loss function

$$
\mathcal{L} = \underbrace{\frac12\| (\hat R - R) \odot M \|_F^2}_{\text{reconstruction}}
+ \underbrace{\mathcal{L}_{\text{sub}}}_{\text{subâ€‘space regulariser}}
+ \underbrace{\frac{\alpha}{2n}\|V\|_F^2 + \frac{\beta}{2}\sum_i \|\theta_i\|_2^2}_{\text{weight decay}}
$$

* **$R$** â€“Â true rating matrix; **$\hat R$** â€“ model prediction.
* \*\*MaskÂ \*\***$M)$** filters out missing ratings so only observed entries contribute.
* **$V$** â€“ trainable item factors; **$\theta_i$** â€“ all other network weights.
* **$V_A$** is *fixed* and only appears inside $\mathcal{L}_{\text{sub}}$.

---

## ðŸ”§Â Hyperâ€‘parameters

> The confidence parameter \$\eta\$ is fixed to **1** as recommended by the authors. Gridâ€‘search therefore explores only the four remaining hyperâ€‘parameters from Tableâ€¯2.

| Hyperâ€‘parameter       | Symbol     | Values searched |
| --------------------- | ---------- | --------------- |
| learning rate         | â€“          | 0.0123, 0.00123 |
| latent dimension      | \$d\$      | 100, 300        |
| item weightâ€‘decay     | \$\alpha\$ | 0.10, 0.20      |
| network weightâ€‘decay  | \$\beta\$  | 0.15, 0.40      |
| projection confidence | \$\eta\$   | **1 (fixed)**   |

Only the **16** combinations of the variable hyperâ€‘parameters are evaluated for each train/val/test split; the best set is selected by the lowest RMSE on the validation set.

## Repository structure

```
â”œâ”€â”€ colab_notebook.ipynb   # oneâ€‘click run & gridâ€‘search in GoogleÂ Colab
â””â”€â”€ README.md              # this file ðŸ˜„
```

> All code lives inside the notebook itself; there is no separate `src/` directory in this reproduction.
